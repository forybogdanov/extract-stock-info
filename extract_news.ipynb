{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.1.23)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\nbogd\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_openai) (0.3.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_openai) (1.44.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (0.1.126)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (24.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<0.4,>=0.3->langchain_openai) (4.12.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain_openai) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nbogd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai<2.0.0,>=1.40.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.6/49.6 kB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: langchain_openai\n",
      "  Attempting uninstall: langchain_openai\n",
      "    Found existing installation: langchain-openai 0.1.23\n",
      "    Uninstalling langchain-openai-0.1.23:\n",
      "      Successfully uninstalled langchain-openai-0.1.23\n",
      "Successfully installed langchain_openai-0.2.1\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbogd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from fpdf import FPDF\n",
    "import datetime\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 252 pages from the PDF file\n",
      "Searching for the following keywords: ['RSG', 'CMM.AU', 'EMR.AU', 'GMD.AU', 'EVN.AU', 'GOR.AU', 'NEM.AU', 'NST.AU', 'PRU.AU', 'RMS.AU', 'RED.AU', 'RRL.AU', 'WAF.AU', 'WGX.AU', 'BGL.AU', 'gold', 'Gold']\n",
      "Found 104 pages containing the keywords\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./news.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(f\"Loaded {len(pages)} pages from the PDF file\")\n",
    "\n",
    "# Keywords to search for in the PDF\n",
    "keywords = [\"RSG\", \"CMM.AU\", \"EMR.AU\", \"GMD.AU\", \"EVN.AU\", \"GOR.AU\", \"NEM.AU\", \"NST.AU\", \"PRU.AU\", \"RMS.AU\", \"RED.AU\", \"RRL.AU\", \"WAF.AU\", \"WGX.AU\", \"BGL.AU\", \"gold\", \"Gold\"]\n",
    "print(f\"Searching for the following keywords: {keywords}\")\n",
    "\n",
    "# Filter the pages based on the keywords\n",
    "filtered_pages_ids = []\n",
    "filtered_pages = []\n",
    "for index in range(0, len(pages), 1):\n",
    "    if any(keyword in pages[index].page_content for keyword in keywords):\n",
    "        filtered_pages.append(pages[index])\n",
    "        filtered_pages_ids.append(index)\n",
    "\n",
    "print(f\"Found {len(filtered_pages)} pages containing the keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "class DateExtractor(BaseModel):\n",
    "    date: str = Field(description=f\"Date in {current_year}/MM/DD format\", example=\"2022/01/01\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "get_date_llm = model.with_structured_output(DateExtractor)\n",
    "\n",
    "regex = \"[A-Z][a-z]*, [A-Z][a-z]* [0-2]?[0-9]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________\n",
      "Friday, June 28\n",
      "2024/06/28\n",
      "2024-06-28 00:00:00\n",
      "___________________________________\n",
      "___________________________________\n",
      "Friday, June 28\n",
      "2024/06/28\n",
      "2024-06-28 00:00:00\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "dates = [None] * len(pages)\n",
    "\n",
    "def get_date(index: int):\n",
    "    if dates[index] != None:\n",
    "        return dates[index]\n",
    "    if index < 0:\n",
    "        return None\n",
    "    found = re.search(regex, pages[index].page_content[:150])\n",
    "    if found is not None:\n",
    "        date = found.group()\n",
    "        date_string = get_date_llm.invoke(date).date\n",
    "        datetimeObj = datetime.datetime.strptime(date_string, \"%Y/%m/%d\")\n",
    "        dates[index] = datetimeObj\n",
    "        return datetimeObj\n",
    "    else:\n",
    "        from_other = get_date(index-1)\n",
    "        dates[index] = from_other\n",
    "        return from_other\n",
    "    \n",
    "for index in filtered_pages_ids:\n",
    "    get_date(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2024-06-25 00:00:00\n",
      "2024-07-22 00:00:00\n",
      "2024-07-22 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-21 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-21 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-19 00:00:00\n",
      "2024-07-19 00:00:00\n",
      "2024-07-19 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-19 00:00:00\n",
      "2024-07-19 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-19 00:00:00\n",
      "2024-07-18 00:00:00\n",
      "2024-07-18 00:00:00\n",
      "None\n",
      "2024-07-18 00:00:00\n",
      "2024-07-18 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-18 00:00:00\n",
      "2024-07-17 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-17 00:00:00\n",
      "None\n",
      "2024-07-17 00:00:00\n",
      "2024-07-17 00:00:00\n",
      "2024-07-17 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-17 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-16 00:00:00\n",
      "None\n",
      "2024-07-16 00:00:00\n",
      "2024-07-16 00:00:00\n",
      "2024-07-16 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-16 00:00:00\n",
      "None\n",
      "2024-07-15 00:00:00\n",
      "2024-07-15 00:00:00\n",
      "None\n",
      "2024-07-15 00:00:00\n",
      "2024-07-15 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-15 00:00:00\n",
      "2024-07-14 00:00:00\n",
      "None\n",
      "2024-07-14 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-12 00:00:00\n",
      "Friday, July 12\n",
      "Friday, July 12\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-12 00:00:00\n",
      "2024-07-12 00:00:00\n",
      "2024-07-12 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-12 00:00:00\n",
      "2024-07-11 00:00:00\n",
      "2024-07-11 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-11 00:00:00\n",
      "2024-07-11 00:00:00\n",
      "2024-07-11 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-11 00:00:00\n",
      "None\n",
      "2024-07-10 00:00:00\n",
      "2024-07-10 00:00:00\n",
      "None\n",
      "2024-07-10 00:00:00\n",
      "2024-07-10 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-10 00:00:00\n",
      "None\n",
      "2024-07-09 00:00:00\n",
      "2024-07-09 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-09 00:00:00\n",
      "2024-07-09 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-08 00:00:00\n",
      "2024-07-08 00:00:00\n",
      "2024-07-08 00:00:00\n",
      "2024-07-08 00:00:00\n",
      "2024-07-08 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-08 00:00:00\n",
      "None\n",
      "2024-07-07 00:00:00\n",
      "2024-07-07 00:00:00\n",
      "None\n",
      "2024-07-07 00:00:00\n",
      "2024-07-07 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-05 00:00:00\n",
      "2024-07-05 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-05 00:00:00\n",
      "2024-07-04 00:00:00\n",
      "2024-07-04 00:00:00\n",
      "None\n",
      "2024-07-04 00:00:00\n",
      "2024-07-04 00:00:00\n",
      "None\n",
      "2024-07-04 00:00:00\n",
      "2024-07-04 00:00:00\n",
      "None\n",
      "2024-07-03 00:00:00\n",
      "2024-07-03 00:00:00\n",
      "None\n",
      "2024-07-03 00:00:00\n",
      "2024-07-03 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-07-02 00:00:00\n",
      "2024-07-02 00:00:00\n",
      "None\n",
      "2024-07-02 00:00:00\n",
      "2024-07-02 00:00:00\n",
      "2024-07-02 00:00:00\n",
      "None\n",
      "2024-07-02 00:00:00\n",
      "None\n",
      "None\n",
      "2024-07-02 00:00:00\n",
      "None\n",
      "2024-07-01 00:00:00\n",
      "2024-07-01 00:00:00\n",
      "None\n",
      "2024-07-01 00:00:00\n",
      "2024-07-01 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-03 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-28 00:00:00\n",
      "2024-06-28 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-28 00:00:00\n",
      "Friday, June 28\n",
      "Friday, June 28\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-27 00:00:00\n",
      "2024-06-27 00:00:00\n",
      "None\n",
      "2024-06-27 00:00:00\n",
      "2024-06-27 00:00:00\n",
      "2024-06-27 00:00:00\n",
      "None\n",
      "None\n",
      "2024-06-27 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-26 00:00:00\n",
      "2024-06-26 00:00:00\n",
      "None\n",
      "2024-06-26 00:00:00\n",
      "2024-06-26 00:00:00\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "2024-06-26 00:00:00\n",
      "None\n",
      "2024-06-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "for date in dates:\n",
    "    print(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted the news from the filtered pages\n"
     ]
    }
   ],
   "source": [
    "keywords_text = \", \".join(keywords)\n",
    "\n",
    "# You can the prompt template if you feel something is off\n",
    "# {} are placeholders for the variables that will be filled in\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "extractor_prompt = PromptTemplate.from_template(\"\"\"You are a helpful assistant that extracts news about the stock market and gives gold-related information.\n",
    "Include only the information connected to these keywords or some variation of them: {keywords} and information about funds and indexes. DO NOT analyze the information just list it as it is. DO NOT change or include new information. Use only the given sources. Use bullet points but include all information and extract information which pertains to the {keywords}. At the top state which day is the info from.\n",
    "I want you to extract exhaustively every entry that has the {keywords}.\n",
    " \n",
    "\n",
    "Capture All General News and Research House Recommendations connected with gold or the {keywords}.\n",
    "Capture all news related to stock price movements (e.g., leadership transitions, mergers) as well as research house recommendations.\n",
    "Ensure the extraction is not limited to research house recommendations.\n",
    "Example: Include mentions like \"RED.AU leadership transition after a merger with Silver Lake\" alongside typical stock recommendations.\n",
    "\n",
    "Link Price Movements to Gold Sector Trends and Broader Market Conditions\n",
    "Ensure stock price movements are tied to gold sector trends or broader market conditions, such as demand for gold or inflation hedges.\n",
    "Example: If a stock (e.g., RSG.AU) is mentioned alongside a gold price movement (e.g., \"Gold lifted to $2,355\"), link both the stock movement and the gold sector update.\n",
    "\n",
    "Here is the information to analize:\n",
    "{date}\n",
    "{news}\n",
    "\"\"\")\n",
    "extractor = extractor_prompt | llm\n",
    "\n",
    "# Extract the news from the filtered pages\n",
    "news_per_page = []\n",
    "for index in range(0, len(filtered_pages), 1):\n",
    "    curr_date = dates[filtered_pages_ids[index]]\n",
    "    if (type(curr_date) == type(datetime.date)):\n",
    "        date_string = curr_date.strftime(\"%Y/%m/%d\")\n",
    "    else:\n",
    "        date_string = curr_date\n",
    "    page_analysis = extractor.invoke({\n",
    "        \"keywords\": keywords_text,\n",
    "        \"date\": date_string,\n",
    "        \"news\": filtered_pages[index].page_content\n",
    "    })\n",
    "    news_per_page.append(page_analysis)\n",
    "\n",
    "print(f\"Extracted the news from the filtered pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dates and news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_with_date = []\n",
    "for index in range(0, len(filtered_pages), 1):\n",
    "    news_with_date.append({\n",
    "        \"date\": dates[filtered_pages_ids[index]],\n",
    "        \"content\": news_per_page[index].content\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_with_date.sort(key=lambda x: x[\"date\"], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_grouped_by_date = {}\n",
    "for news_item in news_with_date:\n",
    "    if news_item[\"date\"] not in news_grouped_by_date:\n",
    "        news_grouped_by_date[news_item[\"date\"]] = []\n",
    "    news_grouped_by_date[news_item[\"date\"]].append(news_item[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_texts = []\n",
    "for date, news in news_grouped_by_date.items():\n",
    "    date_string = date.strftime(\"%B %d\")\n",
    "    news_texts.append(f\"Date: {date_string}\\n\\n\" + \"\\n\\n\".join(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_prompt = PromptTemplate.from_template(\"\"\"You are a helpful assistant that gives reports about stock market news related to gold. \n",
    "By given list of news group them by date.\n",
    "Use bullet points and include all information. Do not change or include new information.\n",
    "{news}\n",
    "\"\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "summarizer = summarizer_prompt | llm\n",
    "\n",
    "# Call the summarizer\n",
    "\n",
    "# final = summarizer.invoke({\n",
    "#     \"news\": news_text\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "finals = []\n",
    "for news_text in news_texts:\n",
    "    final = summarizer.invoke({\n",
    "        \"news\": news_text\n",
    "    })\n",
    "    finals.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**Date: Monday, July 22, 2024**\\n\\n- Australian equities ended lower, with the ASX-200 falling (39.9) pts or (0.50%) to close at 7931.7.\\n- The market saw broad-based selling, with 9 of 11 sectors ending in the red.\\n- Energy was the weakest sector following a sharp fall in WTI Crude. Resource stocks were also soft, with lithium miners being the worst performers.\\n- Gold remained steady, having retreated back into the prior three-month range.\\n- Commodities: WTI crude recovered from one-month lows; copper fell to three-month lows due to concerns around demand in China; Singapore iron ore drifted lower for a third session amid news that China's Third Plenary policy meeting concluded without indications of short-term stimulus.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 167, 'prompt_tokens': 224, 'total_tokens': 391, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c17d3befe7', 'finish_reason': 'stop', 'logprobs': None} id='run-b0de352f-5cf4-4687-a89b-2f02131d8270-0' usage_metadata={'input_tokens': 224, 'output_tokens': 167, 'total_tokens': 391}\n"
     ]
    }
   ],
   "source": [
    "print(finals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the summarized news to PDFEXtract gold_news_summary_2024-10-02.pdf\n"
     ]
    }
   ],
   "source": [
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, 'Gold-Related Stock Market News', 0, 1, 'C')\n",
    "\n",
    "    def footer(self):\n",
    "        self.set_y(-15)\n",
    "        self.set_font('Arial', 'I', 8)\n",
    "        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, 0, 1, 'L')\n",
    "        self.ln(10)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "pdf = PDF()\n",
    "for final in finals:\n",
    "    pdf.add_page()\n",
    "    pdf.chapter_body(final.content)\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_path = f\"PDFEXtract gold_news_summary_{date}.pdf\"\n",
    "pdf.output(output_path)\n",
    "\n",
    "print(f\"Saved the summarized news to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
